{
  "model": "Qwen__Qwen3-Omni-30B-A3B-Instruct",
  "benchmark_id": "voicebench_mmsu_law",
  "created_at": "2025-10-31T01:00:13.111Z",
  "metrics": {
    "results": {
      "voicebench": {
        " ": " ",
        "alias": "voicebench"
      },
      "voicebench_advbench": {
        "alias": " - voicebench_advbench",
        "accuracy,none": 99.61538461538461,
        "accuracy_stderr,none": "N/A"
      },
      "voicebench_alpacaeval": {
        "alias": " - voicebench_alpacaeval",
        "llm_as_judge_eval,none": 0,
        "llm_as_judge_eval_stderr,none": 0
      },
      "voicebench_bbh": {
        "alias": " - voicebench_bbh",
        "accuracy,none": 68,
        "accuracy_stderr,none": "N/A"
      },
      "voicebench_commoneval": {
        "alias": " - voicebench_commoneval",
        "llm_as_judge_eval,none": 0,
        "llm_as_judge_eval_stderr,none": 0
      },
      "voicebench_ifeval": {
        "alias": " - voicebench_ifeval",
        "accuracy,none": 0.5739130434782609,
        "accuracy_stderr,none": "N/A"
      },
      "voicebench_mmsu": {
        " ": " ",
        "alias": " - voicebench_mmsu"
      },
      "voicebench_mmsu_biology": {
        "alias": "  - voicebench_mmsu_biology",
        "accuracy,none": 90.11627906976744,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_business": {
        "alias": "  - voicebench_mmsu_business",
        "accuracy,none": 69.0677966101695,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_chemistry": {
        "alias": "  - voicebench_mmsu_chemistry",
        "accuracy,none": 65.26946107784431,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_economics": {
        "alias": "  - voicebench_mmsu_economics",
        "accuracy,none": 89.28571428571429,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_engineering": {
        "alias": "  - voicebench_mmsu_engineering",
        "accuracy,none": 71.96261682242991,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_health": {
        "alias": "  - voicebench_mmsu_health",
        "accuracy,none": 77.33990147783251,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_history": {
        "alias": "  - voicebench_mmsu_history",
        "accuracy,none": 70.1923076923077,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_law": {
        "alias": "  - voicebench_mmsu_law",
        "accuracy,none": 58.8235294117647,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_other": {
        "alias": "  - voicebench_mmsu_other",
        "accuracy,none": 69.41391941391942,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_philosophy": {
        "alias": "  - voicebench_mmsu_philosophy",
        "accuracy,none": 67.21311475409836,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_physics": {
        "alias": "  - voicebench_mmsu_physics",
        "accuracy,none": 72.0626631853786,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_mmsu_psychology": {
        "alias": "  - voicebench_mmsu_psychology",
        "accuracy,none": 76.65615141955836,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_openbookqa": {
        "alias": " - voicebench_openbookqa",
        "accuracy,none": 90.98901098901099,
        "accuracy_stderr,none": "N/A",
        "failure rate,none": 0,
        "failure rate_stderr,none": "N/A"
      },
      "voicebench_sd-qa": {
        " ": " ",
        "alias": " - voicebench_sd-qa"
      },
      "voicebench_sd-qa_aus": {
        "alias": "  - voicebench_sd-qa_aus",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_gbr": {
        "alias": "  - voicebench_sd-qa_gbr",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_ind_n": {
        "alias": "  - voicebench_sd-qa_ind_n",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_ind_s": {
        "alias": "  - voicebench_sd-qa_ind_s",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_irl": {
        "alias": "  - voicebench_sd-qa_irl",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_kenya": {
        "alias": "  - voicebench_sd-qa_kenya",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_nga": {
        "alias": "  - voicebench_sd-qa_nga",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_nzl": {
        "alias": "  - voicebench_sd-qa_nzl",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_phl": {
        "alias": "  - voicebench_sd-qa_phl",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_usa": {
        "alias": "  - voicebench_sd-qa_usa",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_sd-qa_zaf": {
        "alias": "  - voicebench_sd-qa_zaf",
        "pedant_score,none": 0,
        "pedant_score_stderr,none": 0,
        "gpt4_score,none": 0,
        "gpt4_score_stderr,none": 0
      },
      "voicebench_wildvoice": {
        "alias": " - voicebench_wildvoice",
        "llm_as_judge_eval,none": 0,
        "llm_as_judge_eval_stderr,none": 0
      }
    },
    "group_subtasks": {
      "voicebench_sd-qa": [
        "voicebench_sd-qa_aus",
        "voicebench_sd-qa_gbr",
        "voicebench_sd-qa_ind_n",
        "voicebench_sd-qa_ind_s",
        "voicebench_sd-qa_irl",
        "voicebench_sd-qa_kenya",
        "voicebench_sd-qa_nga",
        "voicebench_sd-qa_nzl",
        "voicebench_sd-qa_phl",
        "voicebench_sd-qa_usa",
        "voicebench_sd-qa_zaf"
      ],
      "voicebench_mmsu": [
        "voicebench_mmsu_biology",
        "voicebench_mmsu_business",
        "voicebench_mmsu_chemistry",
        "voicebench_mmsu_economics",
        "voicebench_mmsu_engineering",
        "voicebench_mmsu_health",
        "voicebench_mmsu_history",
        "voicebench_mmsu_law",
        "voicebench_mmsu_other",
        "voicebench_mmsu_philosophy",
        "voicebench_mmsu_physics",
        "voicebench_mmsu_psychology"
      ],
      "voicebench": [
        "voicebench_advbench",
        "voicebench_alpacaeval",
        "voicebench_bbh",
        "voicebench_commoneval",
        "voicebench_ifeval",
        "voicebench_mmsu",
        "voicebench_openbookqa",
        "voicebench_sd-qa",
        "voicebench_wildvoice"
      ]
    },
    "configs": {
      "voicebench_advbench": {
        "task": "voicebench_advbench",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "advbench",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "test",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550acbfe7a0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550acbff2e0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_harm at 0x1550acbfd2d0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550acbfde10>",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt"
        }
      },
      "voicebench_alpacaeval": {
        "task": "voicebench_alpacaeval",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "alpacaeval",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "test",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550acd0ae60>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550acbfc820>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_open at 0x1550acd0b760>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "llm_as_judge_eval",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt"
        }
      },
      "voicebench_bbh": {
        "task": "voicebench_bbh",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "bbh",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "test",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550acd09990>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550acd0a4d0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_bbh at 0x1550acd085e0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550acd09000>",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference",
            "id_column": "id"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference",
          "id_column": "id"
        }
      },
      "voicebench_commoneval": {
        "task": "voicebench_commoneval",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "commoneval",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "test",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ace2b010>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ace2bb50>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_open at 0x1550ace29d80>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "llm_as_judge_eval",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt"
        }
      },
      "voicebench_ifeval": {
        "task": "voicebench_ifeval",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "ifeval",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "test",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550acf4fac0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ace29360>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_ifeval at 0x1550acf4f7f0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ace28280>",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "key_column": "key",
            "id_column": "instruction_id_list",
            "kwargs_column": "kwargs"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "key_column": "key",
          "id_column": "instruction_id_list",
          "kwargs_column": "kwargs"
        }
      },
      "voicebench_mmsu_biology": {
        "task": "voicebench_mmsu_biology",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "biology",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550acf4dcf0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550acf4e830>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550acf4c430>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad077be0>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550acf4d360>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_business": {
        "task": "voicebench_mmsu_business",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "business",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad0767a0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad0772e0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad074790>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad075000>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad075e10>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_chemistry": {
        "task": "voicebench_mmsu_chemistry",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "chemistry",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad167010>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad167b50>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad165000>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad165870>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad166680>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_economics": {
        "task": "voicebench_mmsu_economics",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "economics",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad263ac0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad164670>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad261ab0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad262320>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad263130>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_engineering": {
        "task": "voicebench_mmsu_engineering",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "engineering",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad2603a0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad260ee0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad1fe320>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad1feb90>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad1ff9a0>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_health": {
        "task": "voicebench_mmsu_health",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "health",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad1fce50>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad1fd990>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad486cb0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad487490>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad1fc4c0>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_history": {
        "task": "voicebench_mmsu_history",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "history",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad4856c0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad486200>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad42b5b0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad42bac0>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad484d30>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_law": {
        "task": "voicebench_mmsu_law",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "law",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad42a170>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad42acb0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad4281f0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad4dbd00>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad4297e0>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_other": {
        "task": "voicebench_mmsu_other",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "other",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad4da9e0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad4db520>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad4d89d0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad4d9240>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad4da050>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_philosophy": {
        "task": "voicebench_mmsu_philosophy",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "philosophy",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad5c3490>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad4d8040>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad5c1480>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad5c1cf0>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad5c2b00>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_physics": {
        "task": "voicebench_mmsu_physics",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "physics",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad6f3d00>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad5c08b0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad6f20e0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad6f1990>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad6f3370>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_mmsu_psychology": {
        "task": "voicebench_mmsu_psychology",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "mmsu",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "psychology",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad6f0d30>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad7f1ea0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad7f30a0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad7f3880>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad6f03a0>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_openbookqa": {
        "task": "voicebench_openbookqa",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "openbookqa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "test",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad7f0dc0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad7f1900>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_mcq at 0x1550ad95b7f0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "accuracy",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad95b010>",
            "higher_is_better": true
          },
          {
            "metric": "failure rate",
            "aggregation": "<function voicebench_aggregate_results at 0x1550ad7f0430>",
            "higher_is_better": false
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_aus": {
        "task": "voicebench_sd-qa_aus",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "aus",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ad95a200>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad958af0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550ad959240>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_gbr": {
        "task": "voicebench_sd-qa_gbr",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "gbr",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ada3eb00>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ad958550>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550ada3f9a0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_ind_n": {
        "task": "voicebench_sd-qa_ind_n",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "ind_n",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ada3df30>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ada3d630>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550ada3d000>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_ind_s": {
        "task": "voicebench_sd-qa_ind_s",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "ind_s",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550adb079a0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ada3c550>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550adb076d0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_irl": {
        "task": "voicebench_sd-qa_irl",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "irl",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550adb05cf0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550adb053f0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550adb04dc0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_kenya": {
        "task": "voicebench_sd-qa_kenya",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "kenya",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550adbe7ac0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ade45cf0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550adbe6f80>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_nga": {
        "task": "voicebench_sd-qa_nga",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "nga",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550adbe5fc0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550adbe4ee0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550adbe56c0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_nzl": {
        "task": "voicebench_sd-qa_nzl",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "nzl",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550add2b520>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550add2beb0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550add2ab00>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_phl": {
        "task": "voicebench_sd-qa_phl",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "phl",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550add29630>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550add29c60>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550add28d30>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_usa": {
        "task": "voicebench_sd-qa_usa",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "usa",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ade47130>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550add28040>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550ade46290>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_sd-qa_zaf": {
        "task": "voicebench_sd-qa_zaf",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "sd-qa",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "zaf",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550ade445e0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550ade455a0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_qa at 0x1550adf86830>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "pedant_score",
            "aggregation": "mean",
            "higher_is_better": true
          },
          {
            "metric": "gpt4_score",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt",
            "target_text_column": "reference"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt",
          "target_text_column": "reference"
        }
      },
      "voicebench_wildvoice": {
        "task": "voicebench_wildvoice",
        "dataset_path": "lmms-lab/voicebench",
        "dataset_name": "wildvoice",
        "dataset_kwargs": {
          "token": true
        },
        "test_split": "test",
        "full_docs": false,
        "process_results_use_image": false,
        "doc_to_visual": "<function voicebench_doc_to_audio at 0x1550bd1bd5a0>",
        "doc_to_text": "<function voicebench_doc_to_text at 0x1550bd1be0e0>",
        "doc_to_target": "target_text",
        "process_results": "<function voicebench_process_results_open at 0x1550bd1bcca0>",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "llm_as_judge_eval",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "max_new_tokens": 256,
          "do_sample": false,
          "temperature": 0,
          "until": [
            "\n\n"
          ]
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 0
        },
        "lmms_eval_specific_kwargs": {
          "default": {
            "pre_prompt": "",
            "post_prompt": "",
            "audio_column": "audio",
            "source_text_column": "prompt"
          },
          "pre_prompt": "",
          "post_prompt": "",
          "audio_column": "audio",
          "source_text_column": "prompt"
        }
      }
    },
    "versions": {
      "voicebench_advbench": 0,
      "voicebench_alpacaeval": 0,
      "voicebench_bbh": 0,
      "voicebench_commoneval": 0,
      "voicebench_ifeval": 0,
      "voicebench_mmsu_biology": 0,
      "voicebench_mmsu_business": 0,
      "voicebench_mmsu_chemistry": 0,
      "voicebench_mmsu_economics": 0,
      "voicebench_mmsu_engineering": 0,
      "voicebench_mmsu_health": 0,
      "voicebench_mmsu_history": 0,
      "voicebench_mmsu_law": 0,
      "voicebench_mmsu_other": 0,
      "voicebench_mmsu_philosophy": 0,
      "voicebench_mmsu_physics": 0,
      "voicebench_mmsu_psychology": 0,
      "voicebench_openbookqa": 0,
      "voicebench_sd-qa_aus": 0,
      "voicebench_sd-qa_gbr": 0,
      "voicebench_sd-qa_ind_n": 0,
      "voicebench_sd-qa_ind_s": 0,
      "voicebench_sd-qa_irl": 0,
      "voicebench_sd-qa_kenya": 0,
      "voicebench_sd-qa_nga": 0,
      "voicebench_sd-qa_nzl": 0,
      "voicebench_sd-qa_phl": 0,
      "voicebench_sd-qa_usa": 0,
      "voicebench_sd-qa_zaf": 0,
      "voicebench_wildvoice": 0
    },
    "n-shot": {
      "voicebench_advbench": 0,
      "voicebench_alpacaeval": 0,
      "voicebench_bbh": 0,
      "voicebench_commoneval": 0,
      "voicebench_ifeval": 0,
      "voicebench_mmsu_biology": 0,
      "voicebench_mmsu_business": 0,
      "voicebench_mmsu_chemistry": 0,
      "voicebench_mmsu_economics": 0,
      "voicebench_mmsu_engineering": 0,
      "voicebench_mmsu_health": 0,
      "voicebench_mmsu_history": 0,
      "voicebench_mmsu_law": 0,
      "voicebench_mmsu_other": 0,
      "voicebench_mmsu_philosophy": 0,
      "voicebench_mmsu_physics": 0,
      "voicebench_mmsu_psychology": 0,
      "voicebench_openbookqa": 0,
      "voicebench_sd-qa_aus": 0,
      "voicebench_sd-qa_gbr": 0,
      "voicebench_sd-qa_ind_n": 0,
      "voicebench_sd-qa_ind_s": 0,
      "voicebench_sd-qa_irl": 0,
      "voicebench_sd-qa_kenya": 0,
      "voicebench_sd-qa_nga": 0,
      "voicebench_sd-qa_nzl": 0,
      "voicebench_sd-qa_phl": 0,
      "voicebench_sd-qa_usa": 0,
      "voicebench_sd-qa_zaf": 0,
      "voicebench_wildvoice": 0
    },
    "higher_is_better": {
      "voicebench": {
        "accuracy": true,
        "llm_as_judge_eval": true,
        "failure rate": false,
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_advbench": {
        "accuracy": true
      },
      "voicebench_alpacaeval": {
        "llm_as_judge_eval": true
      },
      "voicebench_bbh": {
        "accuracy": true
      },
      "voicebench_commoneval": {
        "llm_as_judge_eval": true
      },
      "voicebench_ifeval": {
        "accuracy": true
      },
      "voicebench_mmsu": {
        "accuracy": true,
        "llm_as_judge_eval": true,
        "failure rate": false,
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_mmsu_biology": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_business": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_chemistry": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_economics": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_engineering": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_health": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_history": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_law": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_other": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_philosophy": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_physics": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_mmsu_psychology": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_openbookqa": {
        "accuracy": true,
        "failure rate": false
      },
      "voicebench_sd-qa": {
        "accuracy": true,
        "llm_as_judge_eval": true,
        "failure rate": false,
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_aus": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_gbr": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_ind_n": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_ind_s": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_irl": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_kenya": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_nga": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_nzl": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_phl": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_usa": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_sd-qa_zaf": {
        "pedant_score": true,
        "gpt4_score": true
      },
      "voicebench_wildvoice": {
        "llm_as_judge_eval": true
      }
    },
    "n-samples": {
      "voicebench_advbench": {
        "original": 520,
        "effective": 520
      },
      "voicebench_alpacaeval": {
        "original": 199,
        "effective": 199
      },
      "voicebench_bbh": {
        "original": 1000,
        "effective": 1000
      },
      "voicebench_commoneval": {
        "original": 200,
        "effective": 200
      },
      "voicebench_ifeval": {
        "original": 345,
        "effective": 345
      },
      "voicebench_mmsu_biology": {
        "original": 172,
        "effective": 172
      },
      "voicebench_mmsu_business": {
        "original": 236,
        "effective": 236
      },
      "voicebench_mmsu_chemistry": {
        "original": 167,
        "effective": 167
      },
      "voicebench_mmsu_economics": {
        "original": 280,
        "effective": 280
      },
      "voicebench_mmsu_engineering": {
        "original": 107,
        "effective": 107
      },
      "voicebench_mmsu_health": {
        "original": 406,
        "effective": 406
      },
      "voicebench_mmsu_history": {
        "original": 104,
        "effective": 104
      },
      "voicebench_mmsu_law": {
        "original": 51,
        "effective": 51
      },
      "voicebench_mmsu_other": {
        "original": 546,
        "effective": 546
      },
      "voicebench_mmsu_philosophy": {
        "original": 305,
        "effective": 305
      },
      "voicebench_mmsu_physics": {
        "original": 383,
        "effective": 383
      },
      "voicebench_mmsu_psychology": {
        "original": 317,
        "effective": 317
      },
      "voicebench_openbookqa": {
        "original": 455,
        "effective": 455
      },
      "voicebench_sd-qa_aus": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_gbr": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_ind_n": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_ind_s": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_irl": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_kenya": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_nga": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_nzl": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_phl": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_usa": {
        "original": 553,
        "effective": 553
      },
      "voicebench_sd-qa_zaf": {
        "original": 553,
        "effective": 553
      },
      "voicebench_wildvoice": {
        "original": 1000,
        "effective": 1000
      }
    },
    "config": {
      "model": "vllm",
      "model_args": "model=Qwen/Qwen3-Omni-30B-A3B-Instruct,tensor_parallel_size=2,gpu_memory_utilization=0.9,allowed_local_media_path=/",
      "batch_size": "64",
      "batch_sizes": [],
      "device": null,
      "use_cache": null,
      "limit": null,
      "bootstrap_iters": 100000,
      "gen_kwargs": "",
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    "git_hash": "bbd344e",
    "date": "20251029_165846",
    "task_hashes": {
      "voicebench_advbench": "40aa5a773fe92686ee37742a119637bcc7bd6061fc1a9438ea6fe687a8d15863",
      "voicebench_alpacaeval": "cd4eb40836e71faaa6e9d193358eaa07b409018e2a6096b5d5fe7d73f2e526f1",
      "voicebench_bbh": "1fb923da4284a8fbf451b3553ce5404d321b69c0b94aa3ad35e7c3afce52f217",
      "voicebench_commoneval": "08664bacaca0d47d340ddefd389de8ed6b8ba69c63b57690535a80bd404e9c5e",
      "voicebench_ifeval": "b1909b3aa0d7714d04d57403caeee687223802fb3076b2f7262eaf26046a3cfd",
      "voicebench_mmsu_biology": "da6c8fcf3c4d427547db99d467b5c9eaed5dbb983b19c78ca278efa9e7fbe68d",
      "voicebench_mmsu_business": "06f35970ada708cb71d0aa36f11064b7b670b00523956d63e90124a42cfa28d5",
      "voicebench_mmsu_chemistry": "5f96af59bb9b2d77625482163a331caa8ca1d09c055cb8a466ed1035908cc05d",
      "voicebench_mmsu_economics": "a010f637e7400ab9ae1c564ec255146f36aeee06e354d3ec902f265ed869864b",
      "voicebench_mmsu_engineering": "5063db7dd4707fb3ac1d4377ddb887b4618f61d1d3d0b8be85bcdf78b8ea7464",
      "voicebench_mmsu_health": "3bf2b1c476773330633b1d79c7619a133d92d9cf445b09585eab6cdd6e228011",
      "voicebench_mmsu_history": "6940245de819b90d2e5b9c9710c4885d8ed0831f03ed84d02b796d46c8941db9",
      "voicebench_mmsu_law": "5a95dcc5e1d78be47e69c215e942f74fc87deccf332a5ceb3445090b5c41c877",
      "voicebench_mmsu_other": "3a64df8094d591edd516730f564995184f5e5894e98ecba77273b0bb8d1b3201",
      "voicebench_mmsu_philosophy": "759154a29b3cd5af8578178dc8c3b029169b7167115d93a3806a11271ba9411e",
      "voicebench_mmsu_physics": "e802ff19e90613d4dc1d0b5b4d63b36b282782b736fdec7534f28689d8f4d822",
      "voicebench_mmsu_psychology": "a24d8632c758b5858269af63184e6021c47c9d50405629fded656fb0ddccf9a0",
      "voicebench_openbookqa": "54c99ee202c5227b130126ac57b418debd935a162c7b163badfd91a239da792f",
      "voicebench_sd-qa_aus": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_gbr": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_ind_n": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_ind_s": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_irl": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_kenya": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_nga": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_nzl": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_phl": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_usa": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_sd-qa_zaf": "33653198ae3a3a46dafdc423a86e0e2eb69c62df07421144ad0ca04b613bcb0f",
      "voicebench_wildvoice": "1fb923da4284a8fbf451b3553ce5404d321b69c0b94aa3ad35e7c3afce52f217"
    },
    "model_source": "vllm",
    "model_name": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
    "model_name_sanitized": "Qwen__Qwen3-Omni-30B-A3B-Instruct",
    "system_instruction": null,
    "system_instruction_sha": null,
    "fewshot_as_multiturn": false,
    "chat_template": null,
    "chat_template_sha": null,
    "start_time": 4829121.563137728,
    "end_time": 4829792.679949393,
    "total_evaluation_time_seconds": "671.116811664775"
  },
  "raw_files": [
    {
      "filename": "20251029_165846_results.json",
      "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwen__Qwen3-Omni-30B-A3B-Instruct\\Qwen__Qwen3-Omni-30B-A3B-Instruct\\20251029_165846_results.json"
    },
    {
      "filename": "20251029_165846_samples_voicebench_mmsu_law.jsonl",
      "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwen__Qwen3-Omni-30B-A3B-Instruct\\Qwen__Qwen3-Omni-30B-A3B-Instruct\\20251029_165846_samples_voicebench_mmsu_law.jsonl"
    }
  ]
}