{
  "model": "Qwewn_Qwen2VL",
  "created_at": "2025-10-31T01:05:03.085Z",
  "benchmarks": [
    {
      "benchmark_id": "ok_vqa_val2014",
      "metrics": {
        "results": {
          "ok_vqa_val2014": {
            "alias": "ok_vqa_val2014",
            "exact_match,none": 0.45362663495837874,
            "exact_match_stderr,none": 0.00663602507305181,
            "submission,none": null,
            "submission_stderr,none": "N/A"
          }
        },
        "group_subtasks": {
          "ok_vqa_val2014": []
        },
        "configs": {
          "ok_vqa_val2014": {
            "task": "ok_vqa_val2014",
            "dataset_path": "lmms-lab/OK-VQA",
            "test_split": "val2014",
            "full_docs": false,
            "process_results_use_image": false,
            "doc_to_visual": "<function ok_vqa_doc_to_visual at 0x15520dfe35b0>",
            "doc_to_text": "<function ok_vqa_doc_to_text at 0x15520cf7c0d0>",
            "doc_to_target": "answer",
            "process_results": "<function ok_vqa_process_results at 0x15520cf7c310>",
            "description": "",
            "target_delimiter": " ",
            "fewshot_delimiter": "\n\n",
            "num_fewshot": 0,
            "metric_list": [
              {
                "metric": "exact_match",
                "aggregation": "mean",
                "higher_is_better": true,
                "ignore_case": true,
                "ignore_punctuation": true
              },
              {
                "metric": "submission",
                "aggregation": "<function ok_vqa_aggregate_submissions at 0x15520cf7c700>",
                "higher_is_better": true
              }
            ],
            "output_type": "generate_until",
            "generation_kwargs": {
              "until": [
                "ASSISTANT:"
              ]
            },
            "repeats": 1,
            "should_decontaminate": false,
            "metadata": [
              {
                "version": 0
              }
            ],
            "lmms_eval_specific_kwargs": {
              "default": {
                "pre_prompt": "",
                "post_prompt": "\nWhen the provided information is insufficient, respond with 'Unanswerable'.\nAnswer the question using a single word or phrase."
              },
              "plm": {
                "pre_prompt": "",
                "post_prompt": "\nRespond with one word."
              },
              "pre_prompt": "",
              "post_prompt": "\nWhen the provided information is insufficient, respond with 'Unanswerable'.\nAnswer the question using a single word or phrase."
            }
          }
        },
        "versions": {
          "ok_vqa_val2014": "Yaml"
        },
        "n-shot": {
          "ok_vqa_val2014": 0
        },
        "higher_is_better": {
          "ok_vqa_val2014": {
            "exact_match": true,
            "submission": true
          }
        },
        "n-samples": {
          "ok_vqa_val2014": {
            "original": 5046,
            "effective": 5046
          }
        },
        "config": {
          "model": "qwen2_vl",
          "model_args": "dtype=bfloat16,device_map=auto",
          "batch_size": "2",
          "batch_sizes": [],
          "device": null,
          "use_cache": null,
          "limit": null,
          "bootstrap_iters": 100000,
          "gen_kwargs": "",
          "random_seed": 0,
          "numpy_seed": 1234,
          "torch_seed": 1234,
          "fewshot_seed": 1234
        },
        "git_hash": null,
        "date": "20251026_025159",
        "task_hashes": {
          "ok_vqa_val2014": "729c9462d18bc187ab8472a25494215c5d4ab01b31797faa1d0438073c1fd2a9"
        },
        "model_source": "qwen2_vl",
        "model_name": "",
        "model_name_sanitized": "",
        "system_instruction": null,
        "system_instruction_sha": null,
        "fewshot_as_multiturn": false,
        "chat_template": null,
        "chat_template_sha": null,
        "start_time": 4519114.12497747,
        "end_time": 4520807.777551577,
        "total_evaluation_time_seconds": "1693.652574107051"
      },
      "total_samples": 5046,
      "files": [
        {
          "filename": "20251026_025159_results.json",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_image_20251026_002013\\ok_vqa_val2014.jsonl\\20251026_025159_results.json"
        },
        {
          "filename": "20251026_025159_samples_ok_vqa_val2014.jsonl",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_image_20251026_002013\\ok_vqa_val2014.jsonl\\20251026_025159_samples_ok_vqa_val2014.jsonl"
        },
        {
          "filename": "submissions\\ok_vqa-test-submission-2025-1026-0050-12.json",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_image_20251026_002013\\ok_vqa_val2014.jsonl\\submissions\\ok_vqa-test-submission-2025-1026-0050-12.json"
        }
      ],
      "submissions": []
    },
    {
      "benchmark_id": "arc_challenge",
      "metrics": {
        "results": {
          "arc_challenge": {
            "alias": "arc_challenge",
            "acc,none": 0.12713310580204779,
            "acc_stderr,none": 0.00973475199596078,
            "acc_norm,none": 0.11177474402730375,
            "acc_norm_stderr,none": 0.009207780405950904
          }
        },
        "group_subtasks": {
          "arc_challenge": []
        },
        "configs": {
          "arc_challenge": {
            "task": "arc_challenge",
            "tag": [
              "ai2_arc"
            ],
            "dataset_path": "allenai/ai2_arc",
            "dataset_name": "ARC-Challenge",
            "training_split": "train",
            "validation_split": "validation",
            "test_split": "test",
            "full_docs": false,
            "process_results_use_image": false,
            "doc_to_text": "Question: {{question}}\nAnswer:",
            "doc_to_target": "{{choices.label.index(answerKey)}}",
            "doc_to_choice": "{{choices.text}}",
            "description": "",
            "target_delimiter": " ",
            "fewshot_delimiter": "\n\n",
            "num_fewshot": 0,
            "metric_list": [
              {
                "metric": "acc",
                "aggregation": "mean",
                "higher_is_better": true
              },
              {
                "metric": "acc_norm",
                "aggregation": "mean",
                "higher_is_better": true
              }
            ],
            "output_type": "multiple_choice",
            "repeats": 1,
            "should_decontaminate": true,
            "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
            "metadata": {
              "version": 1
            }
          }
        },
        "versions": {
          "arc_challenge": 1
        },
        "n-shot": {
          "arc_challenge": 0
        },
        "higher_is_better": {
          "arc_challenge": {
            "acc": true,
            "acc_norm": true
          }
        },
        "n-samples": {
          "arc_challenge": {
            "original": 1172,
            "effective": 1172
          }
        },
        "config": {
          "model": "qwen2_vl",
          "model_args": "dtype=bfloat16,device_map=cuda:0",
          "batch_size": "4",
          "batch_sizes": [],
          "device": null,
          "use_cache": null,
          "limit": null,
          "bootstrap_iters": 100000,
          "gen_kwargs": "",
          "random_seed": 0,
          "numpy_seed": 1234,
          "torch_seed": 1234,
          "fewshot_seed": 1234
        },
        "git_hash": null,
        "date": "20251026_022723",
        "task_hashes": {
          "arc_challenge": "5cff4bc97d07094d030e4e85eed895aaa75e2965561cc7302397aa4563866613"
        },
        "model_source": "qwen2_vl",
        "model_name": "",
        "model_name_sanitized": "",
        "system_instruction": null,
        "system_instruction_sha": null,
        "fewshot_as_multiturn": false,
        "chat_template": null,
        "chat_template_sha": null,
        "start_time": 4517638.699668232,
        "end_time": 4517728.82117566,
        "total_evaluation_time_seconds": "90.12150742765516"
      },
      "total_samples": 1172,
      "files": [
        {
          "filename": "20251026_022723_results.json",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_text_20251025_234011\\arc_challenge.jsonl\\20251026_022723_results.json"
        },
        {
          "filename": "20251026_022723_samples_arc_challenge.jsonl",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_text_20251025_234011\\arc_challenge.jsonl\\20251026_022723_samples_arc_challenge.jsonl"
        }
      ],
      "submissions": []
    },
    {
      "benchmark_id": "arc_easy",
      "metrics": {
        "results": {
          "arc_easy": {
            "alias": "arc_easy",
            "acc,none": 0.03324915824915825,
            "acc_stderr,none": 0.003678881507648524,
            "acc_norm,none": 0.05092592592592592,
            "acc_norm_stderr,none": 0.0045111546424629854
          }
        },
        "group_subtasks": {
          "arc_easy": []
        },
        "configs": {
          "arc_easy": {
            "task": "arc_easy",
            "tag": [
              "ai2_arc"
            ],
            "dataset_path": "allenai/ai2_arc",
            "dataset_name": "ARC-Easy",
            "training_split": "train",
            "validation_split": "validation",
            "test_split": "test",
            "full_docs": false,
            "process_results_use_image": false,
            "doc_to_text": "Question: {{question}}\nAnswer:",
            "doc_to_target": "{{choices.label.index(answerKey)}}",
            "doc_to_choice": "{{choices.text}}",
            "description": "",
            "target_delimiter": " ",
            "fewshot_delimiter": "\n\n",
            "num_fewshot": 0,
            "metric_list": [
              {
                "metric": "acc",
                "aggregation": "mean",
                "higher_is_better": true
              },
              {
                "metric": "acc_norm",
                "aggregation": "mean",
                "higher_is_better": true
              }
            ],
            "output_type": "multiple_choice",
            "repeats": 1,
            "should_decontaminate": true,
            "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
            "metadata": {
              "version": 1
            }
          }
        },
        "versions": {
          "arc_easy": 1
        },
        "n-shot": {
          "arc_easy": 0
        },
        "higher_is_better": {
          "arc_easy": {
            "acc": true,
            "acc_norm": true
          }
        },
        "n-samples": {
          "arc_easy": {
            "original": 2376,
            "effective": 2376
          }
        },
        "config": {
          "model": "qwen2_vl",
          "model_args": "dtype=bfloat16,device_map=cuda:0",
          "batch_size": "4",
          "batch_sizes": [],
          "device": null,
          "use_cache": null,
          "limit": null,
          "bootstrap_iters": 100000,
          "gen_kwargs": "",
          "random_seed": 0,
          "numpy_seed": 1234,
          "torch_seed": 1234,
          "fewshot_seed": 1234
        },
        "git_hash": null,
        "date": "20251026_022408",
        "task_hashes": {
          "arc_easy": "1108c2023f66509a668c9379a3343b2df3772121e3b6162daedd55b47aefb420"
        },
        "model_source": "qwen2_vl",
        "model_name": "",
        "model_name_sanitized": "",
        "system_instruction": null,
        "system_instruction_sha": null,
        "fewshot_as_multiturn": false,
        "chat_template": null,
        "chat_template_sha": null,
        "start_time": 4517442.958688504,
        "end_time": 4517625.618553521,
        "total_evaluation_time_seconds": "182.65986501704901"
      },
      "total_samples": 2376,
      "files": [
        {
          "filename": "20251026_022408_results.json",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_text_20251025_234011\\arc_easy.jsonl\\20251026_022408_results.json"
        },
        {
          "filename": "20251026_022408_samples_arc_easy.jsonl",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_text_20251025_234011\\arc_easy.jsonl\\20251026_022408_samples_arc_easy.jsonl"
        }
      ],
      "submissions": []
    },
    {
      "benchmark_id": "hellaswag",
      "metrics": {
        "results": {
          "hellaswag": {
            "alias": "hellaswag",
            "acc,none": 0.06064528978291177,
            "acc_stderr,none": 0.0023819073412748777,
            "acc_norm,none": 0.036048595897231625,
            "acc_norm_stderr,none": 0.0018603011877166289
          }
        },
        "group_subtasks": {
          "hellaswag": []
        },
        "configs": {
          "hellaswag": {
            "task": "hellaswag",
            "tag": [
              "multiple_choice"
            ],
            "dataset_path": "hellaswag",
            "dataset_kwargs": {
              "trust_remote_code": true
            },
            "training_split": "train",
            "validation_split": "validation",
            "full_docs": false,
            "process_results_use_image": false,
            "process_docs": "<function process_docs at 0x15520dfe3760>",
            "doc_to_text": "{{query}}",
            "doc_to_target": "{{label}}",
            "doc_to_choice": "choices",
            "description": "",
            "target_delimiter": " ",
            "fewshot_delimiter": "\n\n",
            "num_fewshot": 0,
            "metric_list": [
              {
                "metric": "acc",
                "aggregation": "mean",
                "higher_is_better": true
              },
              {
                "metric": "acc_norm",
                "aggregation": "mean",
                "higher_is_better": true
              }
            ],
            "output_type": "multiple_choice",
            "repeats": 1,
            "should_decontaminate": false,
            "metadata": {
              "version": 1
            }
          }
        },
        "versions": {
          "hellaswag": 1
        },
        "n-shot": {
          "hellaswag": 0
        },
        "higher_is_better": {
          "hellaswag": {
            "acc": true,
            "acc_norm": true
          }
        },
        "n-samples": {
          "hellaswag": {
            "original": 10042,
            "effective": 10042
          }
        },
        "config": {
          "model": "qwen2_vl",
          "model_args": "dtype=bfloat16,device_map=cuda:0",
          "batch_size": "4",
          "batch_sizes": [],
          "device": null,
          "use_cache": null,
          "limit": null,
          "bootstrap_iters": 100000,
          "gen_kwargs": "",
          "random_seed": 0,
          "numpy_seed": 1234,
          "torch_seed": 1234,
          "fewshot_seed": 1234
        },
        "git_hash": null,
        "date": "20251026_021022",
        "task_hashes": {
          "hellaswag": "4988c8999a55620c5154fcf0b6054bf39a8edbe0884cdf41e6d93df4df1cee1d"
        },
        "model_source": "qwen2_vl",
        "model_name": "",
        "model_name_sanitized": "",
        "system_instruction": null,
        "system_instruction_sha": null,
        "fewshot_as_multiturn": false,
        "chat_template": null,
        "chat_template_sha": null,
        "start_time": 4516617.336561376,
        "end_time": 4517421.949060794,
        "total_evaluation_time_seconds": "804.6124994177371"
      },
      "total_samples": 10042,
      "files": [
        {
          "filename": "20251026_021022_results.json",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_text_20251025_234011\\hellaswag.jsonl\\20251026_021022_results.json"
        },
        {
          "filename": "20251026_021022_samples_hellaswag.jsonl",
          "absolute_path": "C:\\Users\\Kata\\Desktop\\intern\\gui-test-suite\\results\\Qwewn_Qwen2VL\\qwen2vl_text_20251025_234011\\hellaswag.jsonl\\20251026_021022_samples_hellaswag.jsonl"
        }
      ],
      "submissions": []
    }
  ],
  "summary": {
    "start_time": 4517703.279973896,
    "end_time": 4518396.041585388
  }
}